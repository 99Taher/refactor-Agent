import os
import re
import shutil
import requests
import subprocess
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
from fastapi import FastAPI, HTTPException, Header
from pydantic import BaseModel

# Configuration du logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI()

GROQ_API_KEY = os.getenv("GROQ_API_KEY")
GITHUB_TOKEN = os.getenv("GITHUB_TOKEN")
API_SECRET = os.getenv("API_SECRET")

# Param√®tres de performance
MAX_FILES = 10
MAX_WORKERS = 5
GROQ_TIMEOUT = 30
CLONE_DEPTH = 500  # You can increase to 1000 or set to 0 if still issues

class RefactorRequest(BaseModel):
    repo_url: str
    base_ref: str = "main"
    branch: str = "auto-refactor"

def clone_repo(repo_url: str, branch: str, base_ref: str) -> str:
    repo_name = repo_url.split("/")[-1].replace(".git", "")
    clone_url = repo_url.replace("https://", f"https://{GITHUB_TOKEN}@")

    if os.path.exists(repo_name):
        shutil.rmtree(repo_name)

    logger.info(f"Clonage shallow de '{branch}' depth={CLONE_DEPTH} --no-single-branch...")
    subprocess.run([
        "git", "clone",
        "--depth", str(CLONE_DEPTH),
        "--no-single-branch",
        "-b", branch,
        clone_url, repo_name
    ], check=True)

    os.chdir(repo_name)

    # Widen to all branches (you already have this)
    logger.info("Set remote branches to fetch all (*)...")
    subprocess.run(["git", "remote", "set-branches", "origin", "*"], check=True, capture_output=True)

    # Broad shallow fetch of all branch tips first (helps populate remotes/*)
    logger.info("Broad fetch --depth to populate remote refs...")
    broad_fetch = subprocess.run(["git", "fetch", "origin", "--depth=" + str(CLONE_DEPTH)], 
                                 capture_output=True, text=True)
    if broad_fetch.returncode != 0:
        logger.warning(f"Broad fetch warning: {broad_fetch.stderr.strip()}")

    # Explicit fetch for the base branch
    logger.info(f"Explicit fetch origin {base_ref}...")
    explicit_fetch = subprocess.run([
        "git", "fetch", "origin", base_ref, "--depth=" + str(CLONE_DEPTH)
    ], capture_output=True, text=True)
    if explicit_fetch.returncode != 0:
        logger.warning(f"Explicit fetch failed: {explicit_fetch.stderr.strip()}")

    # Fallback: force create remote-tracking ref from FETCH_HEAD if needed
    logger.info("Fallback: create remote-tracking ref if missing...")
    subprocess.run([
        "git", "update-ref", f"refs/remotes/origin/{base_ref}", "FETCH_HEAD"
    ], check=False, capture_output=True)

    # Deepen history a bit more (helps if merge-base is older than depth)
    logger.info("Deepening clone...")
    subprocess.run(["git", "fetch", "--deepen=300"], check=False, capture_output=True)

    # === DEBUG OUTPUT ===
    logger.info("=== GIT DEBUG ===")
    logger.info("Remote branches (git branch -r):")
    logger.info(subprocess.getoutput("git branch -r"))

    logger.info(f"Refs for {base_ref} (git show-ref | grep {base_ref}):")
    logger.info(subprocess.getoutput(f"git show-ref | grep {base_ref} || echo 'No refs found'"))

    logger.info("Last 3 commits on HEAD:")
    logger.info(subprocess.getoutput("git log -n 3 --oneline --decorate"))

    logger.info("=== END DEBUG ===")

    os.chdir("..")
    return repo_name

def get_changed_files(repo_path: str, base_ref: str):
    os.chdir(repo_path)
    try:
        # After all fetches in clone_repo, create a local branch from the fetched base
        logger.info(f"Creating local tracking branch for base: base-{base_ref}")
        # Use FETCH_HEAD from last fetch (explicit one should have set it)
        create_local = subprocess.run([
            "git", "branch", f"base-{base_ref}", "FETCH_HEAD"
        ], capture_output=True, text=True)
        if create_local.returncode != 0:
            logger.warning(f"Local branch create failed: {create_local.stderr.strip()}")
            # Fallback: try from origin if exists, or deepen more
            subprocess.run(["git", "fetch", "--deepen=500"], check=False)

        # DEBUG now
        logger.info("=== GIT DEBUG AFTER LOCAL BRANCH ===")
        logger.info("Branches local + remote:")
        logger.info(subprocess.getoutput("git branch -a"))

        logger.info(f"Log of base-{base_ref} (first 3 commits):")
        logger.info(subprocess.getoutput(f"git log -n 3 --oneline base-{base_ref} || echo 'No log'"))

        logger.info("Log of HEAD:")
        logger.info(subprocess.getoutput("git log -n 3 --oneline HEAD"))

        # Prefer three-dot on local branches
        cmd_three = f"git diff --name-only base-{base_ref}...HEAD"
        logger.info(f"Trying three-dot on local: {cmd_three}")
        try:
            output = subprocess.check_output(cmd_three, shell=True, stderr=subprocess.STDOUT).decode("utf-8").strip()
            files = [f.strip() for f in output.splitlines() if f.strip()]
            logger.info(f"Local three-dot found {len(files)} files")
        except subprocess.CalledProcessError as e:
            logger.warning(f"Three-dot failed: {e.output.decode(errors='ignore')}")
            files = []

        if not files:
            cmd_two = f"git diff --name-only base-{base_ref}..HEAD"
            logger.info(f"Fallback two-dot local: {cmd_two}")
            try:
                output = subprocess.check_output(cmd_two, shell=True, stderr=subprocess.STDOUT).decode("utf-8").strip()
                files = [f.strip() for f in output.splitlines() if f.strip()]
                logger.info(f"Local two-dot found {len(files)} files")
            except:
                files = []

        if files:
            logger.info(f"Changed files sample: {files[:10]}")

        kt_files = [f for f in files if f.endswith(".kt") and os.path.exists(f)]
        logger.info(f".kt files ready for refactor: {len(kt_files)}")

        return kt_files

    except Exception as e:
        logger.exception("Diff computation failed")
        return []
    finally:
        os.chdir("..")

def refactor_file(repo_path: str, filepath: str) -> str:
    """Appelle Groq pour refactoriser un fichier (log cleanup)."""
    full_path = os.path.join(repo_path, filepath)
    try:
        with open(full_path, "r", encoding="utf-8") as f:
            code = f.read()

        if not any(x in code for x in ["Log.", "Logr.", "AppSTLogger.", "AppLogger."]):
            return f"{filepath} - Pas de logs d√©tect√©s"

        url = "https://api.groq.com/openai/v1/chat/completions"
        headers = {
            "Authorization": f"Bearer {GROQ_API_KEY}",
            "Content-Type": "application/json"
        }

        prompt = (
            "You are a Kotlin Refactoring Expert.\n"
            "Your mission: Clean up and deduplicate logging in this Android code.\n\n"
            "1. CONVERSION RULES:\n"
            " - Log.d/i/w/e OR Logr.d/i/w/e -> AppLogger.d/i/w/e(tag, msg)\n"
            " - AppSTLogger.appendLogST(STLevelLog.DEBUG, tag, msg) -> AppLogger.d(tag, msg)\n"
            " - AppSTLogger.appendLogST(STLevelLog.INFO, tag, msg) -> AppLogger.i(tag, msg)\n"
            " - AppSTLogger.appendLogST(STLevelLog.WARN, tag, msg) -> AppLogger.w(tag, msg)\n"
            " - AppSTLogger.appendLogST(STLevelLog.ERROR, tag, msg) -> AppLogger.e(tag, msg)\n\n"
            "2. DEDUPLICATION RULE (CRITICAL):\n"
            " - Merge consecutive lines of AppLogger with EXACT SAME tag and message into ONE.\n"
            " - Example: Multiple AppLogger.e(MODULE, 'text') calls become just one.\n\n"
            "3. IMPORTS:\n"
            " - ADD: 'import com.honeywell.domain.managers.loggerApp.AppLogger'.\n"
            " - REMOVE: android.util.Log, Logr, STLevelLog, and AppSTLogger imports.\n\n"
            "Return ONLY raw source code. NO markdown markers, NO explanations."
        )

        payload = {
            "model": "mixtral-8x7b-32768",
            "messages": [
                {"role": "system", "content": "You are a Kotlin expert. Output only raw source code."},
                {"role": "user", "content": f"{prompt}\n\nCODE:\n{code}"}
            ],
            "temperature": 0
        }

        response = requests.post(url, json=payload, headers=headers, timeout=GROQ_TIMEOUT)
        response.raise_for_status()

        new_code = response.json()["choices"][0]["message"]["content"].strip()
        new_code = re.sub(r"^```kotlin\s*|^```\s*", "", new_code)
        new_code = re.sub(r"\s*```$", "", new_code)

        with open(full_path, "w", encoding="utf-8") as f:
            f.write(new_code)

        return f"{filepath} ‚Üí refactored"

    except requests.exceptions.Timeout:
        return f"{filepath} ‚Üí Groq timeout"
    except Exception as e:
        logger.error(f"Erreur refactor {filepath}: {e}")
        return f"{filepath} ‚Üí Erreur: {str(e)}"

def commit_and_push(repo_path: str):
    os.chdir(repo_path)
    try:
        subprocess.run(["git", "add", "."], check=True)
        subprocess.run(["git", "commit", "-m", "ü§ñ Auto refactor: centralized logging cleanup"], check=True)
        subprocess.run(["git", "push"], check=True)
        logger.info("Commit & push r√©ussi")
    except subprocess.CalledProcessError as e:
        logger.warning(f"Commit/push a √©chou√© (peut-√™tre aucun changement): {e}")
    finally:
        os.chdir("..")

@app.get("/")
async def root():
    return {"message": "Refactor Agent API Is Active"}

@app.post("/refactor")
def run_refactor(
    request: RefactorRequest,
    x_api_key: str = Header(None)
):
    if x_api_key != API_SECRET:
        raise HTTPException(status_code=403, detail="Unauthorized")

    if not GROQ_API_KEY or not GITHUB_TOKEN:
        raise HTTPException(status_code=500, detail="Missing environment variables")

    logger.info(f"D√©but refactor ‚Üí repo: {request.repo_url} | base: {request.base_ref} | branch: {request.branch}")

    try:
        repo_path = clone_repo(request.repo_url, request.branch, request.base_ref)
        files = get_changed_files(repo_path, request.base_ref)

        if not files:
            logger.info("Aucun fichier .kt modifi√© trouv√© ‚Üí fin")
            return {"status": "success", "processed_files": [], "message": "No .kt changes detected"}

        if len(files) > MAX_FILES:
            logger.warning(f"Trop de fichiers ({len(files)}), limit√© √† {MAX_FILES}")
            files = files[:MAX_FILES]

        results = []
        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            future_to_file = {executor.submit(refactor_file, repo_path, f): f for f in files}
            for future in as_completed(future_to_file):
                result = future.result()
                results.append(result)
                logger.info(result)

        if any("refactored" in r for r in results):
            commit_and_push(repo_path)
        else:
            logger.info("Aucun changement r√©el apr√®s refactor ‚Üí pas de commit")

        return {"status": "success", "processed_files": results}

    except subprocess.CalledProcessError as e:
        logger.exception("Erreur git")
        raise HTTPException(500, detail=f"Git error: {e.stderr or str(e)}")
    except Exception as e:
        logger.exception("Erreur globale")
        raise HTTPException(500, detail=f"Server error: {str(e)}")



